{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0a0f4e2",
   "metadata": {},
   "source": [
    "Question 1:\n",
    "Testable Ideas: \n",
    "For an idea to be examined statistically, it must be measurable, observable, and quantifiable.\n",
    "\n",
    "Criteria for a Good Null Hypothesis:\n",
    "It should be clear and specific.\n",
    "It must be testable with data.\n",
    "It needs to be falsifiable.\n",
    "Difference Between Null and Alternative Hypotheses:\n",
    "\n",
    "Null Hypothesis: \n",
    "Assumes no effect or difference.\n",
    "\n",
    "Alternative Hypothesis: \n",
    "Suggests there is a significant effect or difference."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a0d142",
   "metadata": {},
   "source": [
    "Question 2:\n",
    "Sample values: \n",
    "These are individual data points you collect from your sample. For example, if you measured the heights of 10 people, each person's height would be an Sample values\n",
    "\n",
    "Sample mean: \n",
    "This is the average of the sample values. It gives you a summary of your sample data. For example, the average height of the 10 people.\n",
    "\n",
    "Population mean: \n",
    "This is the true average of the entire population. It’s what we want to know, but we typically don’t have access to the whole population, so we estimate it using the sample mean.\n",
    "\n",
    "Hypothesized population mean: \n",
    "This is the value you assume to be true in the null hypothesis. You are testing whether the actual population mean is different from this hypothesized value.\n",
    "\n",
    "When the sentence says, \"outcomes of tests refer to the population parameter, rather than the sample statistic\" it means that hypothesis testing is concerned with making inferences about the population mean based on the sample mean. The result of the test helps determine whether we have enough evidence to conclude that the population mean is different from the hypothesized value.\n",
    "\n",
    "We collect data from a sample to calculate the sample mean. This helps us make a guess about the population mean, which is the true average for the whole group we’re interested in. We start with an assumption about this population mean and use our sample data to test if this assumption is likely true or not.\n",
    "\n",
    "\n",
    "###CHATBOT SESSION###\n",
    "User: Can you explain the difference between the sample mean and the population mean in simple terms?\n",
    "\n",
    "Chatbot: Sure! The sample mean is the average of the data you collect from a small group, or sample, of people or things. For example, if you measure the heights of 10 people, the average height of those 10 people is the sample mean.\n",
    "\n",
    "On the other hand, the population mean is the true average of the entire group you’re interested in, like the average height of everyone in a city. We usually can’t measure the whole population, so we use the sample mean to make a guess about the population mean.\n",
    "\n",
    "User: So how does hypothesis testing fit into this?\n",
    "\n",
    "Chatbot: In hypothesis testing, we often start with an assumption about the population mean, called the null hypothesis. For example, we might assume the average height in a city is 5.5 feet. Then, we collect sample data and use the sample mean to test whether our assumption about the population mean is likely to be true or not.\n",
    "\n",
    "User: And the p-value? How does that help?\n",
    "\n",
    "Chatbot: The p-value tells us how likely it is to get our sample data (or more extreme data) if the null hypothesis is true. A small p-value means it’s unlikely that the sample data would happen if the null hypothesis were correct, so we start to doubt the null hypothesis. A large p-value means the sample data is consistent with the null hypothesis, so we have no reason to doubt it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f407ddba",
   "metadata": {},
   "source": [
    "Question 3:\n",
    "\n",
    "This means that when calculating a p-value, we assume the null hypothesis (the default assumption of no effect or difference) is true. Then, we check how likely it is to observe our data (or something more extreme) under this assumption. If the data we observed is very unlikely under the null hypothesis, the p-value will be small, suggesting that the null hypothesis might not be true."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cccb45c",
   "metadata": {},
   "source": [
    "Question 4:\n",
    "\n",
    "A smaller p-value means the data we observed is very unlikely to happen if the null hypothesis were true. This makes the null hypothesis seem less believable. In other words, the smaller the p-value, the stronger the evidence against the null hypothesis, leading us to doubt its validity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "546e8db4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P-value: 0.0008\n"
     ]
    }
   ],
   "source": [
    "#Question 5\n",
    "import numpy as np\n",
    "\n",
    "# Set the parameters\n",
    "n_trials = 124  # Number of couples\n",
    "n_right = 80    # Observed couples tilting right\n",
    "prob = 0.5      # Null hypothesis probability of tilting right\n",
    "simulations = 10000  # Number of simulations\n",
    "\n",
    "# Perform the binomial simulation\n",
    "np.random.seed(0)\n",
    "sim_results = np.random.binomial(n_trials, prob, simulations)\n",
    "\n",
    "# Calculate the p-value (proportion of simulations with 80 or more right tilts)\n",
    "p_value = np.sum(sim_results >= n_right) / simulations\n",
    "print(f\"P-value: {p_value}\")\n",
    "\n",
    "#so we can get the results below:\n",
    "#If p>0.1, there is no evidence against the null hypothesis.\n",
    "#If 0.1≥p>0.05, there is weak evidence against the null hypothesis.\n",
    "#If 0.05≥p>0.01, there is moderate evidence.\n",
    "#If 0.01≥p>0.001, there is strong evidence.\n",
    "#If p≤0.001, there is very strong evidence against the null hypothesis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "767d0165",
   "metadata": {},
   "source": [
    "Question 6:\n",
    "\n",
    "A smaller p-value does not prove the null hypothesis is false, it only suggests the observed data is unlikely under the null hypothesis. It also can't definitively prove innocence or guilt, it just provides evidence. A very small p-value gives strong evidence against the null hypothesis, but no p-value can definitively prove one side."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0dbc2db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P-value (one-tailed): 0.0004\n"
     ]
    }
   ],
   "source": [
    "#Question 7:\n",
    "import numpy as np\n",
    "\n",
    "# Defining observed value\n",
    "observed = 80  # This is the actual number of couples who tilted their heads right\n",
    "\n",
    "# Set the parameters\n",
    "n_trials = 124  # Total number of couples\n",
    "p_right = 0.5  # Probability under the null hypothesis (50/50 split)\n",
    "n_simulations = 10000  # Number of simulations\n",
    "\n",
    "# Simulate binomial distribution (124 trials, 50% chance per trial)\n",
    "sim_results = np.random.binomial(n_trials, p_right, n_simulations)\n",
    "\n",
    "# Calculate one-tailed p-value (observing right tilts greater than or equal to 80)\n",
    "p_value_one_tailed = np.sum(sim_results >= observed) / n_simulations\n",
    "print(f\"P-value (one-tailed): {p_value_one_tailed}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b47d283",
   "metadata": {},
   "source": [
    "Expected Change in the p-value:\n",
    "In a one-tailed test, since you're only looking at one extreme (one direction), the p-value will generally be smaller compared to a two-tailed test, assuming the observed data supports the direction you're testing for. This is because you are focusing only on one part of the distribution, thus making it easier to find significance in that direction.\n",
    "\n",
    "\n",
    "###CHATBOT SESSION###\n",
    "User: Can you help me adjust code from a two-tailed hypothesis test to a one-tailed test?\n",
    "\n",
    "Chatbot: Sure! In a two-tailed test, you’re checking for extreme values on both sides of the distribution, which means you multiply by 2 to account for both directions (greater than and less than). In a one-tailed test, you only check for extreme values in one direction, so you only consider one end of the distribution.\n",
    "\n",
    "User: How does this change the p-value calculation?\n",
    "\n",
    "Chatbot: For a two-tailed test, the p-value is calculated like this:p_value_two_tailed = 2 * min(np.sum(sim_results >= observed), np.sum(sim_results <= observed)) / simulations\n",
    "For a one-tailed test, you’re only interested in one direction. So, for example, if you're testing whether the observed result is greater than the null hypothesis expectation, the p-value would be:p_value_one_tailed = np.sum(sim_results >= observed) / simulations\n",
    "This will result in a smaller p-value compared to the two-tailed test, assuming the data supports the direction you are testing for, because you're only focusing on one side of the distribution.\n",
    "\n",
    "User: What should I define as the observed value?\n",
    "\n",
    "Chatbot: The observed value is the actual result from your data. For example, if you observed 80 out of 124 couples tilting their heads right, you would define it like this:observed = 80\n",
    "Make sure your simulation setup and the definition of the null hypothesis match this observed value.\n",
    "\n",
    "User: Okay, so in the one-tailed version, I’m only testing if 80 is greater than the expected value under the null hypothesis?\n",
    "\n",
    "Chatbot: Exactly! In the one-tailed test, you’re specifically testing whether the number of couples tilting right is greater than expected. This will give you a smaller p-value if the data supports that direction, making it easier to find statistical significance.\n",
    "\n",
    "User: Thanks, that makes sense!\n",
    "\n",
    "Chatbot: You’re welcome! Let me know if you need further help with the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6444147e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P-value: 0.056664426345121144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_52/3737992153.py:11: DeprecationWarning: 'binom_test' is deprecated in favour of 'binomtest' from version 1.7.0 and will be removed in Scipy 1.12.0.\n",
      "  p_value = binom_test(n_correct, n=n_students, p=p_null, alternative='two-sided')\n"
     ]
    }
   ],
   "source": [
    "#Question 8:\n",
    "import numpy as np\n",
    "from scipy.stats import binom_test\n",
    "\n",
    "# Data\n",
    "n_students = 80\n",
    "n_correct = 49\n",
    "p_null = 0.5  # Null hypothesis proportion\n",
    "\n",
    "# Perform binomial test\n",
    "p_value = binom_test(n_correct, n=n_students, p=p_null, alternative='two-sided')\n",
    "\n",
    "print(f\"P-value: {p_value}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d96797",
   "metadata": {},
   "source": [
    "Problem Introduction\n",
    "Ronald Fisher's famous \"Lady tasting tea\" experiment tested whether Dr. Muriel Bristol could reliably differentiate cups of tea based on the order of milk and tea being poured. In a modern twist, suppose we test 80 STA130 students, asking them to determine whether the milk or tea was poured first. Out of 80 students, 49 correctly identified the order. This analysis will examine whether the result is statistically significant or could have occurred by random guessing.\n",
    "Findings and Discussion\n",
    "If the p-value is low (below a significance threshold, commonly 0.05), we reject the null hypothesis, suggesting that students may indeed have some skill in determining the order of pouring.\n",
    "If the p-value is high, we fail to reject the null hypothesis, implying that the result is consistent with random guessing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d94fc106",
   "metadata": {},
   "source": [
    "Quesion 9:\n",
    "Yes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
